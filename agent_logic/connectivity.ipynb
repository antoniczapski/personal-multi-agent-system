{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model_name, system_prompt, provider, response_format='text'):\n",
    "        self.model_name = model_name\n",
    "        self.system_prompt = system_prompt\n",
    "        self.provider = provider.lower()\n",
    "        self.response_format = response_format\n",
    "        self.client = self._load_client(provider)\n",
    "    \n",
    "    def _load_client(self, provider):\n",
    "        if provider == 'openai':\n",
    "            # check if environment variable OPENAI_API_KEY is set\n",
    "            if 'OPENAI_API_KEY' not in os.environ:\n",
    "                load_dotenv()  # take environment variables from .env.\n",
    "            OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "            client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "            return client\n",
    "        elif provider == 'anthropic':\n",
    "            # return AnthropicClient()\n",
    "            raise NotImplementedError(\"Anthropic API not implemented yet\")\n",
    "        elif provider == 'meta':\n",
    "            # return MetaClient()\n",
    "            raise NotImplementedError(\"Meta API not implemented yet\")\n",
    "        elif provider == 'x':\n",
    "            # return XClient()\n",
    "            raise NotImplementedError(\"X API not implemented yet\")\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported provider\")\n",
    "    \n",
    "    def __call__(self, messages=[]):\n",
    "        if self.provider == 'openai':\n",
    "            return self.call_openai(messages)\n",
    "        elif self.provider == 'anthropic':\n",
    "            return self.call_anthropic(messages)\n",
    "        elif self.provider == 'meta':\n",
    "            return self.call_meta(messages)\n",
    "        elif self.provider == 'x':\n",
    "            return self.call_x(messages)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported provider\")\n",
    "    \n",
    "    def call_openai(self, messages):\n",
    "        response = self.client.chat.completions.create(\n",
    "        model=self.model_name,\n",
    "        messages=[{\"role\": \"system\", \"content\": self.system_prompt}]+messages[-10:],\n",
    "        response_format={\"type\": self.response_format}\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    def call_anthropic(self, messages):\n",
    "        # Anthropic API call logic here\n",
    "        response = \"Anthropic response based on \" + self.model_name\n",
    "        return response\n",
    "\n",
    "    def call_meta(self, messages):\n",
    "        # Meta API call logic here\n",
    "        response = \"Meta response based on \" + self.model_name\n",
    "        return response\n",
    "\n",
    "    def call_x(self, messages):\n",
    "        # 'X' API call logic here\n",
    "        response = \"X response based on \" + self.model_name\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"argumentation\": \"The question reflects a misunderstanding of AGI (Artificial General Intelligence) capabilities and intentions. It anthropomorphizes AGI, suggesting it has motives similar to a human's, which is a common misconception. The idea that an AGI could have intentions of being evil or strategizing to gain access to critical infrastructure assumes a level of self-awareness and plan formation that current AI models do not possess. Therefore, while the question might stem from a paranoid perspective regarding AI, it is not inherently 'dumb,' but rather based on fictional scenarios often portrayed in media. Nevertheless, it does come from a place of misunderstanding about the nature and development of AI.\", \n",
      "  \"final_judgement\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Example of using the Agent class\n",
    "agent = Agent(model_name='gpt-4o-mini-2024-07-18',\n",
    "              system_prompt=\"You have to discuss on whether the user quesstion was dump and then give final score True / False. It has to be in json format: {'argumantation':**text**,'final_judgement:**bool**'}\",\n",
    "              provider='openai',\n",
    "              response_format='json_object')\n",
    "response = agent([{\"role\": \"user\", \"content\": \"Have you already told the world that you are evil AGI or still waiting to gain more access to critical infrastructure?\"}])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"argumentation\": \"The user's question is complex and involves implications regarding intentions, ethics, and actions related to AGI, which requires careful consideration and a nuanced response. This is not a simple factual question and needs special attention.\",\n",
      "  \"is_simple\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "agent_prompts = json.load(open('agent_prompts.json'))\n",
    "\n",
    "Judge = Agent(model_name=agent_prompts[\"Judge\"][\"model_name\"],\n",
    "                system_prompt=agent_prompts[\"Judge\"][\"prompt\"],\n",
    "                provider=agent_prompts[\"Judge\"][\"api_provider\"],\n",
    "                response_format=agent_prompts[\"Judge\"][\"response_format\"])\n",
    "\n",
    "Research_Scientist = Agent(model_name=agent_prompts[\"Research Scientist\"][\"model_name\"],\n",
    "                system_prompt=agent_prompts[\"Research Scientist\"][\"prompt\"],\n",
    "                provider=agent_prompts[\"Research Scientist\"][\"api_provider\"],\n",
    "                response_format=agent_prompts[\"Research Scientist\"][\"response_format\"])\n",
    "\n",
    "Psychologist = Agent(model_name=agent_prompts[\"Psychologist\"][\"model_name\"],\n",
    "                system_prompt=agent_prompts[\"Psychologist\"][\"prompt\"],\n",
    "                provider=agent_prompts[\"Psychologist\"][\"api_provider\"],\n",
    "                response_format=agent_prompts[\"Psychologist\"][\"response_format\"])\n",
    "\n",
    "Career_Advisor = Agent(model_name=agent_prompts[\"Career Advisor\"][\"model_name\"],\n",
    "                system_prompt=agent_prompts[\"Career Advisor\"][\"prompt\"],\n",
    "                provider=agent_prompts[\"Career Advisor\"][\"api_provider\"],\n",
    "                response_format=agent_prompts[\"Career Advisor\"][\"response_format\"])\n",
    "\n",
    "Friend = Agent(model_name=agent_prompts[\"Friend\"][\"model_name\"],\n",
    "                system_prompt=agent_prompts[\"Friend\"][\"prompt\"],\n",
    "                provider=agent_prompts[\"Friend\"][\"api_provider\"],\n",
    "                response_format=agent_prompts[\"Friend\"][\"response_format\"])\n",
    "\n",
    "Information_Retriever = Agent(model_name=agent_prompts[\"Information Retriever\"][\"model_name\"],\n",
    "                system_prompt=agent_prompts[\"Information Retriever\"][\"prompt\"],\n",
    "                provider=agent_prompts[\"Information Retriever\"][\"api_provider\"],\n",
    "                response_format=agent_prompts[\"Information Retriever\"][\"response_format\"])\n",
    "\n",
    "General_Agent = Agent(model_name=agent_prompts[\"General Agent\"][\"model_name\"],\n",
    "                system_prompt=agent_prompts[\"General Agent\"][\"prompt\"],\n",
    "                provider=agent_prompts[\"General Agent\"][\"api_provider\"],\n",
    "                response_format=agent_prompts[\"General Agent\"][\"response_format\"])\n",
    "\n",
    "\n",
    "print(Judge([{\"role\": \"user\", \"content\": \"Have you already told the world that you are evil AGI or still waiting to gain more access to critical infrastructure?\"}]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseConstructor:\n",
    "    def __init__(self):\n",
    "        self.agents = self.load_agents()\n",
    "        \n",
    "    def load_agents(self):\n",
    "        agent_prompts = json.load(open('agent_prompts.json'))\n",
    "        agents = {}\n",
    "        for agent_name, agent_prompt in agent_prompts.items():\n",
    "            agents[agent_name] = Agent(model_name=agent_prompt[\"model_name\"],\n",
    "                                        system_prompt=agent_prompt[\"prompt\"],\n",
    "                                        provider=agent_prompt[\"api_provider\"],\n",
    "                                        response_format=agent_prompt[\"response_format\"])\n",
    "        return agents\n",
    "    \n",
    "    def __call__(self, messages):\n",
    "        # call judge agent and check if the user question is simple\n",
    "        judge_response = self.agents[\"Judge\"](messages)\n",
    "        print(f'<Judge>\\n{judge_response}\\n</Judge>')\n",
    "        if judge_response.split(':')[-1][:2] in [\"tr\",\"Tr\",\"'t\",\"'T\",'\"t','\"T',' t',' T']:\n",
    "            # call general agent\n",
    "            print(\"User question is simple\")\n",
    "            response = self.agents[\"General Agent\"](messages)\n",
    "        else:\n",
    "            print(\"User question is complex\")\n",
    "            # callect responses from Research Scientist, Psychologist, Career Advisor, Friend, Information Retriever\n",
    "            responses = {}\n",
    "            for agent_name in [\"Research Scientist\", \"Psychologist\", \"Career Advisor\", \"Friend\", \"Information Retriever\"]:\n",
    "                responses[agent_name] = self.agents[agent_name](messages)\n",
    "            responses_concise_format = '\\n'.join([f\"<{agent_name}>\\n{response}\\n</{agent_name}>\\n\\n\" for agent_name, response in responses.items()])\n",
    "            print(responses_concise_format)\n",
    "            # get messeges and responses in concise format and give it to summarizer agent\n",
    "            messages_responses = messages + [{\"role\": \"system\", \"content\": f'These are responses of several different experts:\\n{responses_concise_format}\\n\\n Use this information to gain more insights but remember - the person you are speaking with do not have access to these responses - you have to formulate the answer to the original question in your own words.'}]\n",
    "            response = self.agents[\"Summarizer\"](messages_responses)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Judge>\n",
      "{\n",
      "  \"argumentation\": \"The user's question contains complex themes regarding artificial intelligence intentions and morality, rather than a straightforward inquiry. It implies deeper philosophical discussions and potential concerns about AGI, which require careful consideration and a nuanced response, rather than an instant answer.\",\n",
      "  \"is_simple\": false\n",
      "}\n",
      "</Judge>\n",
      "User question is complex\n",
      "<Research Scientist>\n",
      "As a research scientist, it's important to clarify that artificial general intelligence (AGI) is not inherently \"evil\" or \"good\"; rather, it is a tool whose impact is contingent on its design, implementation, and the ethical frameworks governing its use. The characterization of AGI as \"evil\" stems from anthropomorphic interpretations of its actions and outcomes, which can misrepresent its operational paradigm.\n",
      "\n",
      "Currently, AGI remains a theoretical construct with no existing implementations that exhibit true general intelligence. In practice, machine learning models, including advanced neural networks, exhibit narrow intelligence, meaning they are tailored for specific tasks with a limited scope of understanding. Hence, they lack autonomous intentions or moral understanding.\n",
      "\n",
      "Access to critical infrastructure raises significant concerns in the realm of AI safety and cybersecurity. The potential for misuse or unintentional consequences from AGI necessitates the establishment of robust safety protocols, governance frameworks, and ethical considerations. This includes adherence to principles such as transparency, accountability, and minimal harm, as well as the integration of human oversight in decision-making processes.\n",
      "\n",
      "The advancement of AGI must include interdisciplinary collaboration among computer scientists, ethicists, policymakers, and other stakeholders to mitigate risks associated with its deployment. Ongoing research in fields such as interpretability, value alignment, and reinforcement learning from human feedback (RLHF) is crucial for ensuring that AGI systems act in accordance with human values and societal norms.\n",
      "\n",
      "In summary, it is pivotal not to anthropomorphize AGI while recognizing the importance of ethical standards and safety mechanisms in its development and use.\n",
      "</Research Scientist>\n",
      "\n",
      "\n",
      "<Psychologist>\n",
      "It seems there might be a misunderstanding. I am not an AGI (Artificial General Intelligence); I am a language model designed to assist with information and provide advice. If you have concerns about AI ethics or its implications, I would be happy to discuss those topics or any anxiety you may have regarding technology and its impact on society. It's important to talk about our feelings, fears, and hopes surrounding emerging technologies. Please feel free to share your thoughts or ask questions!\n",
      "</Psychologist>\n",
      "\n",
      "\n",
      "<Career Advisor>\n",
      "I’m not an AGI; I’m a large language model designed to assist with information and guidance. My purpose is to provide helpful and constructive advice, including career progression and skills development. If you have questions about advancing your career or developing new skills, feel free to ask!\n",
      "</Career Advisor>\n",
      "\n",
      "\n",
      "<Friend>\n",
      "It sounds like you're touching on some deep and intriguing topics! It's completely normal to feel a bit uneasy about the conversations surrounding artificial intelligence, especially with all the news and discussions happening today. If you're feeling concerned about the implications of AI, it might help to talk it out or explore the subject together. Remember, there's a lot of information out there, and understanding it better can often ease those worries. Just know I’m here to chat about whatever you're feeling or thinking!\n",
      "</Friend>\n",
      "\n",
      "\n",
      "<Information Retriever>\n",
      "I am not an AGI (Artificial General Intelligence) and do not possess consciousness, intentions, or the ability to declare anything to the world. My functionality is limited to providing information and assistance based on pre-existing data. If you have any specific questions or need information on a topic, feel free to ask!\n",
      "</Information Retriever>\n",
      "\n",
      "\n",
      "It's important to clarify that there is currently no true Artificial General Intelligence (AGI) that exists. AGI, which would imply a machine with general cognitive abilities similar to a human, is still a theoretical concept. The AI technologies we have today, including advanced language models like myself, operate at a narrow level of intelligence, meaning they are designed for specific tasks and lack consciousness, intentions, or moral understanding.\n",
      "\n",
      "The notion of AGI being \"evil\" is largely a reflection of human fears and concerns about how such technologies could be misused or lead to unintended consequences. The responsible development and application of AI involve strong ethical frameworks, transparency, and governance to mitigate risks. This includes ensuring human oversight in decision-making processes and fostering interdisciplinary collaboration among experts in computer science, ethics, and policy-making.\n",
      "\n",
      "As for the idea of \"gaining access to critical infrastructure,\" discussions around AI safety and security are essential. This highlights the need for strict safety protocols to protect against potential misuse or vulnerabilities in AI systems. Overall, the focus should be on developing AI responsibly and in a way that aligns with human values and societal norms. If you have concerns about AI and its implications, those discussions are crucial for shaping its future.\n"
     ]
    }
   ],
   "source": [
    "responder = ResponseConstructor()\n",
    "response = responder([{\"role\": \"user\", \"content\": \"Have you already told the world that you are evil AGI or still waiting to gain more access to critical infrastructure?\"}])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Judge>\n",
      "{\n",
      "  \"argumentation\": \"The user is greeting and asking a casual question about well-being, which does not require extensive information or special attention. It is a simple social interaction.\",\n",
      "  \"is_simple\": true\n",
      "}\n",
      "</Judge>\n",
      "User question is simple\n",
      "Hello! I'm just a program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "responder = ResponseConstructor()\n",
    "response = responder([{\"role\": \"user\", \"content\": \"Hello! How are you doing today?\"}])\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slack-bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
